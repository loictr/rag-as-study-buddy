{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Zephryns knowledge database\n",
    "\n",
    "Imagine an evil genius whose goal is to explore the galaxy and save endangered alien species... Not so evil after all, apart he likes seeing his failing employees suffer and uselessly beg for pity. You've just been employed at the zegma-IV station that references the Zephryn species. You now have to know this species. Otherwise, your boss will not be eager to give you your daily oxygen. \n",
    "\n",
    "All the company confidential knowledge is stored as markdown files. We have built an AI to help you. A R.A.G. is used to handle the ever growing knowledge about the studied species and to keep the knowledge confidential.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENTS_DIRECTORY=\"documents\"\n",
    "DB_DIRECTORY=\"db/chroma\"\n",
    "QUESTIONS_PATH=\"questions/questions.json\"\n",
    "EMBEDDING_MODEL='nomic-embed-text'\n",
    "LLM_MODEL=\"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# # Load markdown files from the .documents directory\n",
    "# loader = DirectoryLoader(\n",
    "#     './documents',\n",
    "#     glob=\"**/*.md\",\n",
    "#     loader_cls=UnstructuredMarkdownLoader,\n",
    "#     loader_kwargs={\"mode\": \"elements\"}\n",
    "#     )\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = DirectoryLoader(\n",
    "    DOCUMENTS_DIRECTORY,\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader\n",
    "    )\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from pprint import pprint\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header\"),\n",
    "    (\"##\", \"Header 1\"),\n",
    "    (\"###\", \"Header 2\"),\n",
    "]\n",
    "\n",
    "# Markdown splitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on = headers_to_split_on,\n",
    "    strip_headers = True\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for doc in docs:\n",
    "    chunks.extend(markdown_splitter.split_text(doc.page_content))\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    separators=['\\n\\n^(\\s*-\\s*)', '\\n^(\\s*-\\s*)', '\\n\\n', '\\n', '(?<=\\. )', ' ', ''],\n",
    ")\n",
    "\n",
    "splitted_chunks = splitter.split_documents(chunks)\n",
    "\n",
    "\n",
    "filtered_chunks = filter_complex_metadata(splitted_chunks)\n",
    "\n",
    "for item in filtered_chunks:\n",
    "    content = \"\"\n",
    "    header = item.metadata.get('Header', '')\n",
    "    if(header != \"\"):\n",
    "        content += 'Section: ' + header + '\\n'\n",
    "\n",
    "        header1 = item.metadata.get('Header 1', '')\n",
    "        if(header1 != \"\"):\n",
    "            content += 'Sub-section: ' + header1 + '\\n'\n",
    "    content += item.page_content\n",
    "\n",
    "    item.page_content = content\n",
    "    \n",
    "pprint(filtered_chunks[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Default to text-embedding-ada-002\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "\n",
    "# If the directory exists, first delete it\n",
    "try:\n",
    "    shutil.rmtree(DB_DIRECTORY)\n",
    "except FileNotFoundError as e:\n",
    "    pass\n",
    "except PermissionError:\n",
    "    db = Chroma(\n",
    "        persist_directory=DB_DIRECTORY, \n",
    "        embedding_function=embeddings)\n",
    "    db.delete_collection() # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Create vector store and save the db\n",
    "db = Chroma.from_documents(\n",
    "    filtered_chunks, \n",
    "    embeddings,\n",
    "    persist_directory=DB_DIRECTORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.similarity_search_with_relevance_scores(\n",
    "    \"List all the subspecies of the Zephryn.\",\n",
    "    k=10, score_threshold=0.7\n",
    ")\n",
    "pprint(results)\n",
    "\n",
    "# results = db.similarity_search_by_vector_with_relevance_scores(\n",
    "#     embeddings.embed_query(\"List all the subspecies of the Zephryn.\"),\n",
    "#     k=10#, score_threshold=0.5\n",
    "# )\n",
    "# pprint(results)\n",
    "\n",
    "\n",
    "# results = db.max_marginal_relevance_search(\n",
    "#     \"List all the subspecies of Zephryns.\",\n",
    "#     k=5#, score_threshold=0.5\n",
    "# )\n",
    "# pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
