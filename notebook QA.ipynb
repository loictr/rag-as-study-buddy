{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    "\n",
    "db = Chroma(\n",
    "    persist_directory='./db/chroma', \n",
    "    embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain for a QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# retriever = db.as_retriever(\n",
    "#     search_type=\"similarity\",\n",
    "#     search_kwargs={'k': 10}\n",
    "# )\n",
    "\n",
    "# retriever = db.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={'k': 7, 'score_threshold': 0.4}\n",
    "# )\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 10, 'lambda_mult': 0.6}\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer or if you don't have enough information in the context, just say that you don't know, don't try to make up an answer.\n",
    "Be very concise and to the point. Don't write more than 2 sentences. Do not start your answer with things like \"based on the context\" or \"I think\".\n",
    "\n",
    "Context:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\" \n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        doc.page_content for doc in docs\n",
    "    )\n",
    "\n",
    "qa_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"docs\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# get the source documents\n",
    "qa_chain_with_source = RunnableParallel(\n",
    "    {\"docs\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=qa_chain)\n",
    "\n",
    "def print_answer(input):\n",
    "    answer = qa_chain_with_source.invoke(input)\n",
    "    print(answer['answer'])\n",
    "    print(\"--------------------------\")\n",
    "    pprint(answer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "question = \"Where do Windriders often spend their lives?\"\n",
    "# question = \"What does the Skydancer eat?\"\n",
    "# question = \"What are the physical differences between the Windrider and the Skydancer?\"\n",
    "\n",
    "print_answer(question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
